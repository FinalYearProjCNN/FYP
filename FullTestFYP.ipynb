{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yp0V7qWuKfML"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ISe4tocQL7Xt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-06 16:04:59.371744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGA\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneticAlgorithm\n",
            "File \u001b[0;32m~/Downloads/FYP/GA.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m GradientBoostingClassifier\n\u001b[0;32m---> 10\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGeneticAlgorithm\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m     \u001b[39m# Define the problem\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     GENERATIONS \u001b[39m=\u001b[39m \u001b[39m25\u001b[39m\n\u001b[1;32m     14\u001b[0m     POPULATION_SIZE \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n",
            "File \u001b[0;32m~/Downloads/FYP/GA.py:71\u001b[0m, in \u001b[0;36mGeneticAlgorithm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_genotype\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_rate_of_decay(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_num_epochs(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_learning_rate())\n\u001b[0;32m---> 71\u001b[0m population \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_genotype() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(POPULATION_SIZE)]\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrossover\u001b[39m(\u001b[39mself\u001b[39m, parent1, parent2):\n\u001b[1;32m     74\u001b[0m     RATE_OF_DECAY_LENGTH \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
            "File \u001b[0;32m~/Downloads/FYP/GA.py:71\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_genotype\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_rate_of_decay(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_num_epochs(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_learning_rate())\n\u001b[0;32m---> 71\u001b[0m population \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mrandom_genotype() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(POPULATION_SIZE)]\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrossover\u001b[39m(\u001b[39mself\u001b[39m, parent1, parent2):\n\u001b[1;32m     74\u001b[0m     RATE_OF_DECAY_LENGTH \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ],
      "source": [
        "import nbimporter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import ResNet50\n",
        "import seaborn as sn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import skimage.io\n",
        "import keras.backend as K\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras import Model, Sequential\n",
        "import keras.models\n",
        "from keras.layers import *\n",
        "from keras.models import * \n",
        "from keras import optimizers, applications\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from GA import GeneticAlgorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ASe8TtLWMXD-"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    \n",
        "    train_path = \"/Users/macair/Downloads/FYP/faces/train\"\n",
        "    test_path = \"/Users/macair/Downloads/FYP/faces/test\"\n",
        "\n",
        "    batch_size = 64\n",
        "    train_datagen = image.ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    test_datagen = image.ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1)\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True)\n",
        "\n",
        "\n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        subset='validation',\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('generators.pickle', 'wb') as f:\n",
        "    pickle.dump((train_generator, test_generator, validation_generator), f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "75Wlc3qYdVL6"
      },
      "outputs": [],
      "source": [
        "def f1_score(y_true, y_pred): \n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return 2*(precision*recall)/(precision+recall+K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1WUn6ExtZ0BW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-04 21:39:34.196209: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),  \n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "        f1_score,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import GA\n",
        "ga = GA.GeneticAlgorithm(pop_size=50, num_generations=100,\n",
        "                              mutation_rate=0.01, crossover_rate=0.8, gene_length=10)\n",
        "\n",
        "ga.evolve_population()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_individual = ga.best_genotype()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u1flxkBiYJda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_170\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_170 (Flatten)       (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_340 (Dense)           (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dense_341 (Dense)           (None, 7)                 7175      \n",
            "                                                                 \n",
            " dropout_170 (Dropout)       (None, 7)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,984,519\n",
            "Trainable params: 9,451,527\n",
            "Non-trainable params: 22,532,992\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def define_model():\n",
        "    base_model = applications.ResNet50(weights='imagenet',\n",
        "                                    include_top=False,\n",
        "                                    input_shape=(48, 48, 3))\n",
        "\n",
        "    for layer in base_model.layers[:-4]:\n",
        "        layer.trainable = False\n",
        "\n",
        "        model = keras.Sequential()\n",
        "        model.add(base_model)\n",
        "        model.add(keras.layers.Flatten())\n",
        "        model.add(keras.layers.Dense(1024, activation=\"relu\"))\n",
        "        model.add(keras.layers.Dense(7, activation=\"softmax\"))\n",
        "        model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    input_shape = (None, 48, 48, 3)\n",
        "    model.build(input_shape)\n",
        "    model.compile(optimizers.Adam(learning_rate=0.0001,\n",
        "                  decay=1e-4), loss='MSE', metrics=METRICS)\n",
        "    model.summary()\n",
        "    model.save('mymodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    checkpoint = ModelCheckpoint(\"resnet50.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
        "    early = EarlyStopping(verbose =1, monitor='val_loss', min_delta=0.0001, patience=20, mode='auto')\n",
        "    lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\n",
        "    prediction = model.predict(validation_generator)\n",
        "    hist = model.fit(train_generator,\n",
        "                     validation_data=validation_generator,\n",
        "                     epochs=5,\n",
        "                     callbacks=[checkpoint, early, lrd],\n",
        "                     verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0nYg0UEmw_K"
      },
      "outputs": [],
      "source": [
        "#filename = \"./Completed_model\"\n",
        "#save_model(model, filename)\n",
        "#loaded_model = keras.models.load_model(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NUHCrRxNbOZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n",
        "    \n",
        "    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n",
        "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
        "\n",
        "    ax1.plot(range(1, len(acc) + 1), acc)\n",
        "    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
        "    ax1.set_title('History of Accuracy')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend(['training', 'validation'])\n",
        "\n",
        "\n",
        "    ax2.plot(range(1, len(loss) + 1), loss)\n",
        "    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
        "    ax2.set_title('History of Loss')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend(['training', 'validation'])\n",
        "    \n",
        "    ax3.plot(range(1, len(auc) + 1), auc)\n",
        "    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n",
        "    ax3.set_title('History of AUC')\n",
        "    ax3.set_xlabel('Epochs')\n",
        "    ax3.set_ylabel('AUC')\n",
        "    ax3.legend(['training', 'validation'])\n",
        "    \n",
        "    ax4.plot(range(1, len(precision) + 1), precision)\n",
        "    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n",
        "    ax4.set_title('History of Precision')\n",
        "    ax4.set_xlabel('Epochs')\n",
        "    ax4.set_ylabel('Precision')\n",
        "    ax4.legend(['training', 'validation'])\n",
        "    \n",
        "    ax5.plot(range(1, len(f1) + 1), f1)\n",
        "    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n",
        "    ax5.set_title('History of F1-score')\n",
        "    ax5.set_xlabel('Epochs')\n",
        "    ax5.set_ylabel('F1 score')\n",
        "    ax5.legend(['training', 'validation'])\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "Train_Val_Plot(hist.history['accuracy'],hist.history['val_accuracy'],\n",
        "               hist.history['loss'],hist.history['val_loss'],\n",
        "               hist.history['auc'],hist.history['val_auc'],\n",
        "               hist.history['precision'],hist.history['val_precision'],\n",
        "               hist.history['f1_score'],hist.history['val_f1_score']\n",
        "              )\n",
        "\n",
        "y_pred = model.predict(test_generator)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmrTZWrqZ2q5"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        #print(\"Normalized confusion matrix\")\n",
        "    #else:\n",
        "        #print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_true, y_pred, classes=faces, normalize=True, title='Normalized confusion matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
